{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEE 443 - Final Project - Image Captioning:\n",
    "\n",
    "## Group 10:\n",
    "\n",
    "Ayhan Okuyan, Baris Akcin, Emre Donmez, Hasan Emre Erdemoglu, Ruzgar Eserol, Suleyman Taylan Topaloglu\n",
    "\n",
    "### Inception Encoder: (Part 2/3)\n",
    "\n",
    "1. Import Transfer Learning Models and do the encoding using these models, (Intricasies will be explained in the report).\n",
    "2. Export necessary output to be used in the continuing notebooks.\n",
    "\n",
    "**Note:** Images must be on working directory under images subdirectory. The rest of the structure will be built by this notebook.\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Making Section:\n",
    "\n",
    "1. Build necessary directories, some files needed are already put within root folder.\n",
    "2. Unpack given dataset nd download images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" # Disable GPU\n",
    "# See the directories construct directories if needed:\n",
    "root_dir = os.getcwd()\n",
    "imgs_dir = root_dir + '\\\\images'\n",
    "exports_dir = root_dir + '\\\\exports'\n",
    "\n",
    "print(root_dir)\n",
    "\n",
    "if not os.path.exists(exports_dir):\n",
    "    os.mkdir(exports_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning Section:\n",
    "\n",
    "Try on different encoding schemes on CNN-Encoder part. With a given RNN-Decoder piece, these networks may give different performance. \n",
    "If time permits, there will be 4 different CNNs to be used in transfer learning. For RNN implementations, refer to that notebook.\n",
    "\n",
    "1. Inception v3 model definition\n",
    "3. Inception ResNet v2 (to be implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image \n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "def inception_load_image(path):\n",
    "    img = image.load_img(path, target_size=(299, 299, 3))\n",
    "    imgar = image.img_to_array(img)\n",
    "    imgar = np.expand_dims(imgar, axis=0)\n",
    "    imgar = preprocess_input(imgar)\n",
    "    return imgar\n",
    "\n",
    "def inception_transfer_model():\n",
    "    tf.keras.backend.clear_session() # clears previous session if this code is run multiple time\n",
    "    # This is necessary, as re-running these segments may stack up models \n",
    "\n",
    "    inception_model = InceptionV3(include_top=True, weights='imagenet', input_shape=(299,299,3))\n",
    "    inception_model.trainable = False\n",
    "\n",
    "    # Check layers via inception_model.summary()\n",
    "    #inception_model.summary()\n",
    "\n",
    "    inception_tx_layer = inception_model.get_layer('avg_pool') # mixed10 is the final layer with notop layout. \n",
    "\n",
    "    new_input = inception_model.input\n",
    "    x = inception_tx_layer.output\n",
    "\n",
    "    inception_tx_model = tf.keras.Model(outputs=x, inputs=new_input) # directly make a model from it.\n",
    "    #inception_tx_model.summary()\n",
    "\n",
    "    inception_img_size = K.int_shape(inception_tx_model.input)[1:3]\n",
    "    print('Image size: ', inception_img_size)\n",
    "\n",
    "    inception_tx_values_size = K.int_shape(inception_tx_layer.output)\n",
    "    print('Vector size of transfer values: ', inception_tx_values_size)\n",
    "    return inception_tx_model\n",
    "\n",
    "def inception_encode_image(image_dir, img_id,model):\n",
    "    image = inception_load_image(image_dir+img_id)\n",
    "    image = image.reshape((1, image.shape[1], image.shape[2], image.shape[3]))\n",
    "    image = preprocess_input(image)\n",
    "    encoding = model.predict(image)\n",
    "    #encoding = np.reshape(encoding, encoding.shape[1])\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding & Pickling:\n",
    "\n",
    "For each of the model, realize everything, encode the images and save them using pickle serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_tx_model = inception_transfer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "os.chdir(imgs_dir) # change to training directory\n",
    "inception_v3_exp_dir = exports_dir + '\\\\inception_v3_encodings'\n",
    "\n",
    "if not os.path.exists(inception_v3_exp_dir):\n",
    "    os.mkdir(inception_v3_exp_dir)\n",
    "\n",
    "for img in tqdm(os.listdir()):\n",
    "    if os.path.exists(inception_v3_exp_dir + '\\\\' + img +'.npy'):\n",
    "        continue\n",
    "    else:\n",
    "        tmp = inception_encode_image(os.getcwd() + '\\\\', img, inception_tx_model)\n",
    "        np.save(inception_v3_exp_dir + '\\\\' + img +'.npy', tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps: \n",
    "In the next step, we will import these encodings to another notebook and construct an RNN model to do actual image captioning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
