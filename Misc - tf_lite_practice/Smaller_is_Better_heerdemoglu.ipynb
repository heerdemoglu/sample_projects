{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Smaller is Better - heerdemoglu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smi3VYAQ7Q34"
      },
      "source": [
        "# Project Notes:\n",
        "I was going to push everything to GitLab with a requirements.txt and pull everything here from GitLab; but I had a hardware issue with my computer so I had to take everything to Google Colaboratory. You may ignore my pushes in GitLab except for this notebook as they will not be the finalized form.\n",
        "[This](https://www.oreilly.com/content/compressing-and-regularizing-deep-neural-networks/) and [this webpage](https://blog.xmartlabs.com/2020/06/01/how-to-speed-up-inference-in-your-deep-learning-model/) has very good insights and analysis as well.\n",
        "\n",
        "My aim with this notebook is to try out different approaches to test what might work the best. All methods that reduce the file size or parameter sizes has their own advantages and disadvantages. Each technique can be examined in detail and the best approach can be selected after testing many possibilities. \n",
        "\n",
        "\n",
        "## List of ideas to try:\n",
        "* Weight Sharing\n",
        "* Model Pruning\n",
        "* Knowledge Distillation: Non destructive; but we define a learner model.\n",
        "* Low Rank Matrix and Tensor Decompositions: See [this](https://arxiv.org/abs/2006.06443) link.\n",
        "* Quantization (Quantization Aware Training OR Post-Training Quantization): Available with TensorFlow.\n",
        "* Clustering: See [this](https://www.tensorflow.org/model_optimization/guide/clustering/clustering_example) link.\n",
        "\n",
        "## Notes:\n",
        "* Made the methods such a way that it can prune any given h5 or tf model file.\n",
        "* Further (deeper) methods can be trained on top of this network given with the code segment. Deeper models can achieve higher capacities and can be pruned even further. Clustering and quantization can compress the network size even more; then this can be converted to tflite model for mobile deployment.\n",
        "\n",
        "# Install necessary dependencies: \n",
        "\n",
        "* \"tensorflow-model-optimization\" contains many algorithms that involve network pruning, quantization and encodings. This library is an easy way to deploy models fast; however it is not compatible with many types of layers that TF has.\n",
        "* 'tfcoreml' and 'coremltools' are used to convert TensorFlow models to CoreML outputs for better compatibility of iOS environment. I could directly use CoreML but I don't have access to necessary tools.\n",
        "* Also the second cell checks the device (GPU) information for further reference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StgjQ6h9-sRQ",
        "outputId": "513a721a-bffc-4a11-b135-d117297b7264"
      },
      "source": [
        "!pip install tensorflow-model-optimization\n",
        "# Run these later as they significantly slow down the training process.\n",
        "# !pip install --upgrade tfcoreml\n",
        "# !pip install --upgrade coremltools"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\r\u001b[K     |██                              | 10kB 17.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 14.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 40kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 51kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 81kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 102kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 112kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 122kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 133kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 143kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 153kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 163kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (0.1.6)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMH5y_tvexBB",
        "outputId": "319d3ed6-7786-463d-ac67-a2ff4cefa5c6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jun 17 01:28:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mmb4aXp7Vwl"
      },
      "source": [
        "# Method Definitions:\n",
        "\n",
        "All methods that are going to be used in the runtime is listed below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFn-HA__-mze"
      },
      "source": [
        "# Tested on Colaboratory with GPU, Tensorflow 2.4.1\n",
        "# Tested on MacBook Pro M1 with CPU/GPU, Tensorflow 2.4.0\n",
        "\n",
        "import tensorflow as tf\n",
        "# work through pip install tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "def build_model(input_shape):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.BatchNormalization(input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    model.add(tf.keras.layers.BatchNormalization(input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    model.add(tf.keras.layers.BatchNormalization(input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(256))\n",
        "    model.add(tf.keras.layers.Activation('relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(10))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train(x_train, y_train, x_test, y_test, lr, epochs, batch_size, savedir):\n",
        "    \"\"\"\n",
        "    Train the model given the dataset and the global parameters (LR, EPOCHS and BATCH_SIZE).\n",
        "\n",
        "    The model is automatically saved after the training.\n",
        "\n",
        "    \"\"\"\n",
        "    model = build_model(x_train.shape[1:])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['categorical_accuracy'],\n",
        "    )\n",
        "    # print(model.summary())\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.fit(\n",
        "        x=x_train.astype(np.float32),\n",
        "        y=y_train.astype(np.float32),\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Train elapsed time: {} seconds\".format(end_time - start_time))\n",
        "\n",
        "    model.save(savedir, overwrite=True)\n",
        "    return model\n",
        "\n",
        "\n",
        "def test(x_test, y_test, loaddir):\n",
        "    \"\"\"\n",
        "    Load any saved model and evaluate it against the test set.\n",
        "    \"\"\"\n",
        "    model = tf.keras.models.load_model(loaddir)\n",
        "\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['categorical_accuracy'],\n",
        ")   \n",
        "    # print(model.summary())\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    scores = model.evaluate(x_test, y_test)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Test elapsed time: {} seconds\".format(end_time - start_time))\n",
        "    return scores\n",
        "\n",
        "\n",
        "def pruned_train(x_train, y_train, loaddir, lr, val_split, epochs, batch_size,\n",
        "                 prune_summaries,  # uncomment to add prune summary callback directory to save logs.\n",
        "                 savedir):\n",
        "\n",
        "    # Load the model:\n",
        "    model = tf.keras.models.load_model(loaddir)\n",
        "    num_images = x_train.shape[0] * (1 - val_split)\n",
        "    end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "    # Define model for pruning. # ToDo: Further optimization can work good; put these to arguments of method.\n",
        "    pruning_params = {\n",
        "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.40,\n",
        "                                                                 final_sparsity=0.80,\n",
        "                                                                 begin_step=0,\n",
        "                                                                 end_step=end_step,\n",
        "                                                                 frequency=100)\n",
        "    }\n",
        "\n",
        "    model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "    # Pruning method requires a recompile.\n",
        "    model_for_pruning.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['categorical_accuracy'],\n",
        "    )\n",
        "\n",
        "    # model_for_pruning.summary()   # for debugging, uncomment if you want to inspect.\n",
        "\n",
        "    # Train for given amount of time.\n",
        "    callbacks = [\n",
        "        tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "        tfmot.sparsity.keras.PruningSummaries(log_dir=prune_summaries),\n",
        "    ]\n",
        "\n",
        "    model_for_pruning.fit(x_train, y_train,\n",
        "                          batch_size=batch_size, epochs=epochs, validation_split=val_split,\n",
        "                          callbacks=callbacks)\n",
        "\n",
        "    final_model = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "    final_model.summary() # for debugging, uncomment if you want to inspect.\n",
        "\n",
        "    final_model.save(savedir, overwrite=True)\n",
        "    return final_model\n",
        "\n",
        "\n",
        "def apply_custom_quantization(layer):\n",
        "    \"\"\"\n",
        "    Helper function that quantizes all layers except for batch normalization, and maxpooling\n",
        "    as these are not supported by TensorFlow 2.4.\n",
        "\n",
        "    # ToDo: Hacky ways are possible. Different models may work; but more engineering and different network\n",
        "    #       implementations would be needed.\n",
        "    # ToDo: eLu quantization is also not accepted by tensorflow; relu is accepted.\n",
        "    \"\"\"\n",
        "    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        if not isinstance(layer, tf.keras.layers.MaxPooling2D):\n",
        "            return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "    return layer\n",
        "\n",
        "def quantized_train(x_train, y_train, loaddir, lr, val_split, epochs, batch_size,\n",
        "                    savedir):\n",
        "\n",
        "    # Load the model:\n",
        "    model = tf.keras.models.load_model(loaddir)\n",
        "    \n",
        "    # Proceed with quantization:\n",
        "    annotated_model = tf.keras.models.clone_model(model, clone_function=apply_custom_quantization)\n",
        "\n",
        "    q_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
        "    # q_aware_model.summary()\n",
        "\n",
        "    # Pruning method requires a recompile.\n",
        "    q_aware_model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['categorical_accuracy'],\n",
        "    )\n",
        "\n",
        "    q_aware_model.fit(x_train, y_train,\n",
        "                  batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "    q_aware_model.summary() # for debugging, uncomment if you want to inspect.\n",
        "\n",
        "    q_aware_model.save(savedir, overwrite=True)\n",
        "    return q_aware_model\n",
        "\n",
        "# ToDo: Uses apply_custom_quantization, however this method has bugs listed, commented within.\n",
        "def quantized_test(x_test, y_test, loaddir):\n",
        "    \"\"\"\n",
        "    Applies quantization to the given model.\n",
        "    \"\"\"\n",
        "    model = tf.keras.models.load_model(loaddir)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    scores = model.evaluate(x_test, y_test)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Test elapsed time: {} seconds\".format(end_time - start_time))\n",
        "    return scores\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hvtn9Sa77oh"
      },
      "source": [
        "# Runtime Cells: \n",
        "\n",
        "* First, run the vanilla model this will be the baseline.\n",
        "* Secondly, pruning will be applied to the trained vanilla model, using tensorflow's optimization libraries (tensorflow-model-optimization).\n",
        "* Thirdly, quantization aware training will be done. Knowledge distillation will be tested.\n",
        "* Finally, this model will be converted to TFLite model for mobile deployment.\n",
        "\n",
        "## Extras:\n",
        "\n",
        "* PyTorch implementation would use the same pipeline; analogous methods are available. \n",
        "* TensorFlow does not allow pruning of many types of layers such as MaxPooling and Batch Normalization. It allows writing custom code to prune or quantize such layers but it requires more analysis and engineering before implementation.\n",
        "* This means the model can be further compressed. The cells will report their model loss and accuracy; and all models trained and optimized will be downloaded to your PC at the end of the file for your further inspection.\n",
        "\n",
        "\n",
        "It would be good to try out very deep models that can achieve 95% accuracy on Fashion MNIST or more (current SotA at 96%). We can prune such networks to have better accuracies afteer pruning. One other advantage is that it might be possible to reach or surpass 90% accuracy limit after quantization losses as well.\n",
        "\n",
        "## Notes:\n",
        "\n",
        "* Almost no difference after pruning procedure. Regular network has a size of 18 MB; pruned method has 6 MB. The percentage difference between the networks are 1% in favor of the vanilla model.\n",
        "\n",
        "* Should check whether clustering first would give better results; than prune first and the cluster. When multiple methods are used; we can look at different combinations of implementing the compression.\n",
        "\n",
        "* Quantization aware training gives good results; but its performance is mostly visible after encoding/compressing the network to TFLite format/\n",
        "\n",
        "* Knowledge distillation is a good way to completely reduce number of parameters(other methods mask filter weights). Less number of parameter imply faster inference times. We need to aim for at least 24 FPS for real-time processing. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRN69jAElRV-"
      },
      "source": [
        "## Weight Pruning Compression:\n",
        "\n",
        "This is used to mask weakest model weights to zero so that the compression algorithms can reduce the file size.\n",
        "\n",
        "Initial observations indicate that it does not help in inference time; but the loss in accuracy is minimal and there is a significant decrease in model size. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7q_bks9-nhu",
        "outputId": "07bfc45c-f801-46a0-aa69-a7d1909d1c8a"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# from fashion_mnist import train, test, pruned_train\n",
        "import tensorflow as tf\n",
        "\n",
        "# Global Variables:\n",
        "LR = 1E-3\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "\n",
        "# Load the dataset:\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Add a trailing unitary dimension to make a 3D multidimensional array (tensor):\n",
        "# N x 28 x 28 --> N x 28 x 28 x 1\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "# Convert the labels from integers to one-hot encoding:\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Comment/uncomment the following two lines as needed:\n",
        "print('Starting Training:')\n",
        "model = train(x_train, y_train, x_test, y_test, LR, EPOCHS, BATCH_SIZE, 'fashion_mnist_model')\n",
        "print(\"\\n\")\n",
        "\n",
        "# Check and list scores of the regular model given with this code segment.\n",
        "print('Starting Testing:')\n",
        "scores = test(x_test, y_test, './fashion_mnist_model')\n",
        "print(\"\\n\")\n",
        "print('Model Validation Loss:', scores[0])\n",
        "print('Model Validation Accuracy:', scores[1])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Starting Training:\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 25s 9ms/step - loss: 0.5867 - categorical_accuracy: 0.7891 - val_loss: 0.3476 - val_categorical_accuracy: 0.8733\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.3733 - categorical_accuracy: 0.8676 - val_loss: 0.3235 - val_categorical_accuracy: 0.8843\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.3238 - categorical_accuracy: 0.8860 - val_loss: 0.3162 - val_categorical_accuracy: 0.8853\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.2947 - categorical_accuracy: 0.8941 - val_loss: 0.2795 - val_categorical_accuracy: 0.8949\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.2796 - categorical_accuracy: 0.9012 - val_loss: 0.2711 - val_categorical_accuracy: 0.9044\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.2637 - categorical_accuracy: 0.9047 - val_loss: 0.2573 - val_categorical_accuracy: 0.9106\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.2474 - categorical_accuracy: 0.9113 - val_loss: 0.2508 - val_categorical_accuracy: 0.9122\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.2354 - categorical_accuracy: 0.9143 - val_loss: 0.2558 - val_categorical_accuracy: 0.9064\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.2270 - categorical_accuracy: 0.9178 - val_loss: 0.2476 - val_categorical_accuracy: 0.9095\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.2162 - categorical_accuracy: 0.9202 - val_loss: 0.2306 - val_categorical_accuracy: 0.9192\n",
            "Train elapsed time: 143.01352500915527 seconds\n",
            "INFO:tensorflow:Assets written to: fashion_mnist_model/assets\n",
            "\n",
            "\n",
            "Starting Testing:\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2306 - categorical_accuracy: 0.9192\n",
            "Test elapsed time: 2.8691580295562744 seconds\n",
            "\n",
            "\n",
            "Model Validation Loss: 0.23055659234523773\n",
            "Model Validation Accuracy: 0.9192000031471252\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 28, 28, 1)         4         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 128)       204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 256)         819456    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               590080    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,619,470\n",
            "Trainable params: 1,619,084\n",
            "Non-trainable params: 386\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlFsYvrN7wOj",
        "outputId": "b2a21f52-8aa3-4a52-be5d-6870459077a6"
      },
      "source": [
        "# Model pruning using TF's optimization libraries. PyTorch port is also available.\n",
        "# The support of this API is limited; but allows writing custom pruning and quantization functions.\n",
        " \n",
        "# Uses 5 epochs of training with 80% sparsity. We can add additional callbacks and take checkpoints. \n",
        "# By this way we can optimize over objectives: the best (smallest) model and the highest accuracy.\n",
        "print('Starting Training:')\n",
        "pruned_model = pruned_train(x_train, y_train, './fashion_mnist_model', 0.0001, 0.1, 2, BATCH_SIZE,\n",
        "                            './temp', \n",
        "                            './pruned_fashion_mnist_model')\n",
        "print(\"\\n\")\n",
        "\n",
        "# Observe and evaluate results.\n",
        "print('Starting Testing:')\n",
        "scores = test(x_test, y_test, './pruned_fashion_mnist_model')\n",
        "\n",
        "print('\\n')\n",
        "print('Pruned Validation Loss:', scores[0])\n",
        "print('Pruned Validation Accuracy:', scores[1])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Training:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2191: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "  5/844 [..............................] - ETA: 2:11 - loss: 0.2027 - categorical_accuracy: 0.9344WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0141s vs `on_train_batch_begin` time: 0.0418s). Check your callbacks.\n",
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0141s vs `on_train_batch_end` time: 0.0574s). Check your callbacks.\n",
            "844/844 [==============================] - 25s 24ms/step - loss: 0.2657 - categorical_accuracy: 0.9024 - val_loss: 0.2256 - val_categorical_accuracy: 0.9180\n",
            "Epoch 2/2\n",
            "844/844 [==============================] - 19s 23ms/step - loss: 0.3632 - categorical_accuracy: 0.8699 - val_loss: 0.2255 - val_categorical_accuracy: 0.9160\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 28, 28, 1)         4         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 128)       204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 256)         819456    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               590080    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,619,470\n",
            "Trainable params: 1,619,084\n",
            "Non-trainable params: 386\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: ./pruned_fashion_mnist_model/assets\n",
            "\n",
            "\n",
            "Starting Testing:\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2615 - categorical_accuracy: 0.9053\n",
            "Test elapsed time: 1.6007919311523438 seconds\n",
            "\n",
            "\n",
            "Pruned Validation Loss: 0.26146548986434937\n",
            "Pruned Validation Accuracy: 0.9053000211715698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62EoOXJgq2tp"
      },
      "source": [
        "## Quantization Aware Training:\n",
        "\n",
        "Do the training quantization aware and mask the unnecessary capacity of the network by weight pruning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XijsOvJV7428",
        "outputId": "58045a93-7c18-41c4-a653-0a612b19d06a"
      },
      "source": [
        "# Quantization Aware Training:\n",
        "print('Starting training.')\n",
        "q_aware_model = quantized_train(x_train, y_train, './fashion_mnist_model', LR, 0.1, 5, BATCH_SIZE,\n",
        "                            './qaware_fashion_mnist_model')\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training.\n",
            "Epoch 1/5\n",
            "844/844 [==============================] - 22s 24ms/step - loss: 0.2269 - categorical_accuracy: 0.9184 - val_loss: 0.1890 - val_categorical_accuracy: 0.9323\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 20s 24ms/step - loss: 0.2149 - categorical_accuracy: 0.9231 - val_loss: 0.1856 - val_categorical_accuracy: 0.9335\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 20s 24ms/step - loss: 0.1983 - categorical_accuracy: 0.9270 - val_loss: 0.1624 - val_categorical_accuracy: 0.9372\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 20s 24ms/step - loss: 0.1957 - categorical_accuracy: 0.9280 - val_loss: 0.1827 - val_categorical_accuracy: 0.9345\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 20s 24ms/step - loss: 0.1880 - categorical_accuracy: 0.9299 - val_loss: 0.1677 - val_categorical_accuracy: 0.9385\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 28, 28, 1)         4         \n",
            "_________________________________________________________________\n",
            "quant_conv2d (QuantizeWrappe (None, 28, 28, 64)        1795      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "quant_dropout (QuantizeWrapp (None, 14, 14, 64)        1         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "quant_conv2d_1 (QuantizeWrap (None, 14, 14, 128)       205187    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "quant_dropout_1 (QuantizeWra (None, 7, 7, 128)         1         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "quant_conv2d_2 (QuantizeWrap (None, 7, 7, 256)         819971    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "quant_dropout_2 (QuantizeWra (None, 3, 3, 256)         1         \n",
            "_________________________________________________________________\n",
            "quant_flatten (QuantizeWrapp (None, 2304)              1         \n",
            "_________________________________________________________________\n",
            "quant_dense (QuantizeWrapper (None, 256)               590085    \n",
            "_________________________________________________________________\n",
            "quant_activation (QuantizeWr (None, 256)               3         \n",
            "_________________________________________________________________\n",
            "quant_dropout_3 (QuantizeWra (None, 256)               1         \n",
            "_________________________________________________________________\n",
            "quant_dense_1 (QuantizeWrapp (None, 10)                2575      \n",
            "_________________________________________________________________\n",
            "quant_activation_1 (Quantize (None, 10)                1         \n",
            "=================================================================\n",
            "Total params: 1,620,394\n",
            "Trainable params: 1,619,084\n",
            "Non-trainable params: 1,310\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, dropout_layer_call_fn, dropout_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./qaware_fashion_mnist_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./qaware_fashion_mnist_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xitse8uA8iSy",
        "outputId": "79a78e04-2bae-4a91-fffe-c2f69e948ed0"
      },
      "source": [
        "# Quantization awareness slows down the training and inference times; \n",
        "# but it should not be problem after we convert to TFLite models.\n",
        "print('Starting testing.')\n",
        "scores = quantized_test(x_test, y_test, './qaware_fashion_mnist_model')\n",
        "\n",
        "print('\\n')\n",
        "print('Pruned Validation Loss:', scores[0])\n",
        "print('Pruned Validation Accuracy:', scores[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting testing.\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.2363 - categorical_accuracy: 0.9181\n",
            "Test elapsed time: 2.7808849811553955 seconds\n",
            "\n",
            "\n",
            "Pruned Validation Loss: 0.23629344999790192\n",
            "Pruned Validation Accuracy: 0.9180999994277954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP919XVp4zOQ"
      },
      "source": [
        "# Prune the quantization aware network\n",
        "# NOT APPLICABLE: As quantize aware layers are not prunable by TensorFlow.\n",
        "# See the error output below:\n",
        "# print('Starting Training:')\n",
        "# pruned_model = pruned_train(x_train, y_train, './qaware_fashion_mnist_model', 0.0001, 0.1, 2, BATCH_SIZE,\n",
        "#                             './temp', \n",
        "#                             './pruned_qaware_fashion_mnist_model')\n",
        "# print(\"\\n\")\n",
        "\n",
        "# # Observe and evaluate results.\n",
        "# print('Starting Testing:')\n",
        "# scores = test(x_test, y_test, './pruned_qaware_fashion_mnist_model')\n",
        "\n",
        "# print('\\n')\n",
        "# print('Pruned Validation Loss:', scores[0])\n",
        "# print('Pruned Validation Accuracy:', scores[1])\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItL8ZTRulNWj"
      },
      "source": [
        "## Knowledge Distillation:\n",
        "\n",
        "First knowledge distillation can be used to extract a smaller model in a non-destructive way. Then the weight pruning and quantization can be used to further process the networks.\n",
        "\n",
        "The good part here is that we construct a smaller network and teach the network using our current model. This smaller network uses the has lesser neurons; which means better inference time performance. With addition of pruning and quantization; the model size can be compressed as well.\n",
        "\n",
        "However, one caveat is that learner network has to be built by us as well; so this means we have to engineer a good (and small) learner network for our task as well.\n",
        "\n",
        "Distiller was able to reduce the inference time to 0.88 seconds (more than 50% reduction).\n",
        "\n",
        "Number of parameters were shrunk significantly but at the cost of less model accuracy. More engineering is needed on student network to optimize for this issue. (Accuracy dropped from 90% to "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryO6umJhlLbT"
      },
      "source": [
        "# Taken from: https://keras.io/examples/vision/knowledge_distillation/#setup\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        \"\"\" Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Compute losses\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "            )\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the loss\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcO995A6FpAf"
      },
      "source": [
        "# Create the teacher:\n",
        "def build_teacher(input_shape):\n",
        "    teacher = tf.keras.models.Sequential([tf.keras.layers.BatchNormalization(input_shape=input_shape),\n",
        "                                        tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "                                        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "                                        tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "                                        tf.keras.layers.BatchNormalization(input_shape=input_shape),\n",
        "                                        tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='relu'),\n",
        "                                        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "                                        tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "                                        tf.keras.layers.BatchNormalization(input_shape=input_shape),\n",
        "                                        tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='relu'),\n",
        "                                        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "                                        tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "                                        tf.keras.layers.Flatten(),\n",
        "                                        tf.keras.layers.Dense(256),\n",
        "                                        tf.keras.layers.Activation('relu'),\n",
        "                                        tf.keras.layers.Dropout(0.5),\n",
        "                                        tf.keras.layers.Dense(10),\n",
        "                                        tf.keras.layers.Activation('softmax')],\n",
        "                                        name=\"teacher\"\n",
        "                                    )\n",
        "    return teacher\n",
        "\n",
        "def build_student(input_shape):\n",
        "\n",
        "    student = keras.Sequential(\n",
        "        [   tf.keras.layers.BatchNormalization(input_shape=input_shape),\n",
        "            layers.Conv2D(64, (5,5), strides=(2, 2), padding=\"same\"),\n",
        "            layers.Activation('relu'),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "            tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "            tf.keras.layers.BatchNormalization(input_shape=input_shape),\n",
        "            layers.Conv2D(256, (5,5), strides=(2, 2), padding=\"same\"),\n",
        "            layers.Activation('relu'),\n",
        "            tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "            tf.keras.layers.Dropout(0.25),\n",
        "         \n",
        "            layers.Flatten(),\n",
        "            tf.keras.layers.Dense(256),\n",
        "            tf.keras.layers.Activation('relu'),\n",
        "            layers.Dense(10),\n",
        "            tf.keras.layers.Activation('softmax')],\n",
        "        name=\"student\",\n",
        "    )\n",
        "    return student\n",
        "\n",
        "teacher = build_teacher(x_train.shape[1:])\n",
        "student = build_student(x_train.shape[1:])\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG_6ZNp_msei",
        "outputId": "29987d44-927b-476b-9d37-5a539b0d7fc4"
      },
      "source": [
        "# Compile student:\n",
        "student.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['categorical_accuracy'],\n",
        "    )\n",
        "\n",
        "# Train teacher as usual\n",
        "teacher.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['categorical_accuracy'],\n",
        "    )\n",
        "\n",
        "# Train and evaluate teacher on data.\n",
        "teacher.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "scores = teacher.evaluate(x_test, y_test)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print('Test time elapsed:', str(end_time-start_time))\n",
        "\n",
        "print('\\n')\n",
        "print('Validation Loss:', scores[0])\n",
        "print('Validation Accuracy', scores[1])\n",
        "\n",
        "teacher.save(\"./teacher_model\", overwrite=True)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.6032 - categorical_accuracy: 0.7824\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3912 - categorical_accuracy: 0.8602\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3399 - categorical_accuracy: 0.8791\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3151 - categorical_accuracy: 0.8870\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2936 - categorical_accuracy: 0.8946\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2773 - categorical_accuracy: 0.9002\n",
            "Test time elapsed: 1.4647762775421143\n",
            "\n",
            "\n",
            "Validation Loss: 0.27731695771217346\n",
            "Validation Accuracy 0.9002000093460083\n",
            "INFO:tensorflow:Assets written to: ./teacher_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./teacher_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPPZftpvOkZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c731b0c-9176-429c-a6af-ba48165354fa"
      },
      "source": [
        "# Initialize and compile distiller\n",
        "distiller = Distiller(student=student, teacher=teacher)\n",
        "distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=10,\n",
        ")\n",
        "\n",
        "# Distill teacher to student\n",
        "distiller.fit(x_train, y_train, epochs=3)\n",
        "\n",
        "# Evaluate student on test dataset\n",
        "distiller.evaluate(x_test, y_test)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4870: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`categorical_crossentropy` received `from_logits=True`, but '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 13s 6ms/step - categorical_accuracy: 0.8393 - student_loss: 0.4399 - distillation_loss: 6.1183e-05\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 12s 6ms/step - categorical_accuracy: 0.8841 - student_loss: 0.3110 - distillation_loss: 3.4895e-05\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 12s 6ms/step - categorical_accuracy: 0.8969 - student_loss: 0.2797 - distillation_loss: 3.1615e-05\n",
            "313/313 [==============================] - 1s 3ms/step - categorical_accuracy: 0.8980 - student_loss: 0.2805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8980000019073486, 0.286588579416275]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VimZu7gh7p_z"
      },
      "source": [
        "# distiller.save(\"./distilled_student_model\", overwrite=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ctcxv8S8GH8"
      },
      "source": [
        "# Mobile Deployment:\n",
        "\n",
        "Deploy the models to TFLite and CoreML Outputs.\n",
        "\n",
        "* Choosing 8 bits as I assume we would be working on CPU; not GPU of the device. \n",
        "* If GPU was to be used; the best option is to do 16 bit quantization for better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhQ9g95V8NpN"
      },
      "source": [
        "## TFLite Deployment:\n",
        "\n",
        "The cells below can be combined together in a loop; this way is not efficient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e8T_jumi_Xi"
      },
      "source": [
        "def export_tflite_model(modeldir, tf_filename):\n",
        "    converter = tf.lite.TFLiteConverter.from_saved_model(modeldir)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    lite_model = converter.convert()\n",
        "\n",
        "    # save model\n",
        "    tflite_model_name = tf_filename\n",
        "    open(tflite_model_name, \"wb\").write(lite_model)\n",
        "\n",
        "    print('Saved TFLite model to:', lite_model)\n",
        "    return"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c01fXjdXIKO0",
        "outputId": "4e7a4899-3c43-4ca1-a59c-e40584366812"
      },
      "source": [
        "# Export models:\n",
        "export_tflite_model('./fashion_mnist_model',\"tflite_model.tflite\")\n",
        "export_tflite_model('./pruned_fashion_mnist_model',\"tflite_pruned_model.tflite\")\n",
        "export_tflite_model('./qaware_fashion_mnist_model',\"tflite_qaware_model.tflite\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD4D6pK18QcT"
      },
      "source": [
        "## CoreML Deployment:\n",
        "\n",
        "I have not worked with CoreML before; but it is possible to convert TensorFlow and PyTorch models do CoreML models. \n",
        "\n",
        "[This link](https://medium.com/maxims-passion-project/convert-a-tensorflow-model-to-core-ml-with-coremltools-8c304f1af2f6) shows a brief introduction of this for tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJFQ6oZt9t-I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9edec429-8785-4f49-f8c4-32a14690e20b"
      },
      "source": [
        "# Run these now as they significantly slow down the training process.\n",
        "!pip install --upgrade tfcoreml\n",
        "!pip install --upgrade coremltools"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tfcoreml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/0c/cfbc828342685ca78ac7bf7126670a0d3bac2f1d7c3560289a3a62b93a18/tfcoreml-2.0-py3-none-any.whl (44kB)\n",
            "\r\u001b[K     |███████▍                        | 10kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 20kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 30kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 40kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from tfcoreml) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tfcoreml) (3.12.4)\n",
            "Collecting tensorflow<=1.14,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 1.3MB/s \n",
            "\u001b[?25hCollecting coremltools>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/b0/14c37edf39a9b32c2c9c7aa3e27ece4ef4f5b2dd2c950102661a106520f1/coremltools-4.1-cp37-none-manylinux1_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tfcoreml) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.1.0->tfcoreml) (57.0.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 32.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (1.34.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (0.8.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 29.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (0.4.0)\n",
            "Collecting attr\n",
            "  Downloading https://files.pythonhosted.org/packages/de/be/ddc7f84d4e087144472a38a373d3e319f51a6faf6e5fc1ae897173675f21/attr-0.3.1.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: sympy in /usr/local/lib/python3.7/dist-packages (from coremltools>=0.8->tfcoreml) (1.7.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from coremltools>=0.8->tfcoreml) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from coremltools>=0.8->tfcoreml) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: attrs in /usr/local/lib/python3.7/dist-packages (from coremltools>=0.8->tfcoreml) (21.2.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from coremltools>=0.8->tfcoreml) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow<=1.14,>=1.5.0->tfcoreml) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<=1.14,>=1.5.0->tfcoreml) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<=1.14,>=1.5.0->tfcoreml) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->coremltools>=0.8->tfcoreml) (1.2.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->coremltools>=0.8->tfcoreml) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow<=1.14,>=1.5.0->tfcoreml) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow<=1.14,>=1.5.0->tfcoreml) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow<=1.14,>=1.5.0->tfcoreml) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow<=1.14,>=1.5.0->tfcoreml) (3.7.4.3)\n",
            "Building wheels for collected packages: attr\n",
            "  Building wheel for attr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for attr: filename=attr-0.3.1-cp37-none-any.whl size=2458 sha256=880c6aefdb3ad1198f71f5d4846cc11c5688753b5e59f112a3c7fb9d0b824a29\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/96/9b/1f8892a707d17095b5a6eab0275da9d39e68e03a26aee2e726\n",
            "Successfully built attr\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, keras-applications, tensorboard, tensorflow, attr, coremltools, tfcoreml\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed attr-0.3.1 coremltools-4.1 keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 tfcoreml-2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: coremltools in /usr/local/lib/python3.7/dist-packages (4.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: attr in /usr/local/lib/python3.7/dist-packages (from coremltools) (0.3.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.20,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: sympy in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.7.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from coremltools) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from coremltools) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: attrs in /usr/local/lib/python3.7/dist-packages (from coremltools) (21.2.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->coremltools) (1.2.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->coremltools) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.1.0->coremltools) (57.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYTOZeLx97Gz"
      },
      "source": [
        "# Download files:\n",
        "\n",
        "* Note that Google Colaboratory includes a directory called \"sample_data\"; this directory is also downloaded; but unrelated with the files that we are interested in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4rDdJwtVqEbS",
        "outputId": "8b65f215-f1ac-4bf3-d913-04920b6a00ea"
      },
      "source": [
        "!zip -r content.zip /content/\n",
        "from google.colab import files\n",
        "files.download(\"content.zip\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/ (stored 0%)\n",
            "  adding: content/.config/ (stored 0%)\n",
            "  adding: content/.config/configurations/ (stored 0%)\n",
            "  adding: content/.config/configurations/config_default (deflated 15%)\n",
            "  adding: content/.config/.last_survey_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/gce (stored 0%)\n",
            "  adding: content/.config/active_config (stored 0%)\n",
            "  adding: content/.config/.last_update_check.json (deflated 22%)\n",
            "  adding: content/.config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/logs/ (stored 0%)\n",
            "  adding: content/.config/logs/2021.06.15/ (stored 0%)\n",
            "  adding: content/.config/logs/2021.06.15/13.37.22.745818.log (deflated 53%)\n",
            "  adding: content/.config/logs/2021.06.15/13.36.40.402408.log (deflated 91%)\n",
            "  adding: content/.config/logs/2021.06.15/13.37.15.895583.log (deflated 86%)\n",
            "  adding: content/.config/logs/2021.06.15/13.37.40.569743.log (deflated 53%)\n",
            "  adding: content/.config/logs/2021.06.15/13.37.39.858399.log (deflated 55%)\n",
            "  adding: content/.config/logs/2021.06.15/13.36.59.704686.log (deflated 53%)\n",
            "  adding: content/.config/config_sentinel (stored 0%)\n",
            "  adding: content/tflite_model.tflite (deflated 14%)\n",
            "  adding: content/fashion_mnist_model/ (stored 0%)\n",
            "  adding: content/fashion_mnist_model/variables/ (stored 0%)\n",
            "  adding: content/fashion_mnist_model/variables/variables.index (deflated 70%)\n",
            "  adding: content/fashion_mnist_model/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/fashion_mnist_model/saved_model.pb (deflated 89%)\n",
            "  adding: content/fashion_mnist_model/keras_metadata.pb (deflated 93%)\n",
            "  adding: content/fashion_mnist_model/assets/ (stored 0%)\n",
            "  adding: content/tflite_pruned_model.tflite (deflated 67%)\n",
            "  adding: content/temp/ (stored 0%)\n",
            "  adding: content/temp/train/ (stored 0%)\n",
            "  adding: content/temp/train/events.out.tfevents.1623893462.7aaf0e7f661b.profile-empty (deflated 5%)\n",
            "  adding: content/temp/train/events.out.tfevents.1623893457.7aaf0e7f661b.59.33759.v2 (deflated 92%)\n",
            "  adding: content/temp/train/plugins/ (stored 0%)\n",
            "  adding: content/temp/train/plugins/profile/ (stored 0%)\n",
            "  adding: content/temp/train/plugins/profile/2021_06_17_01_31_02/ (stored 0%)\n",
            "  adding: content/temp/train/plugins/profile/2021_06_17_01_31_02/7aaf0e7f661b.kernel_stats.pb (deflated 90%)\n",
            "  adding: content/temp/train/plugins/profile/2021_06_17_01_31_02/7aaf0e7f661b.tensorflow_stats.pb (deflated 77%)\n",
            "  adding: content/temp/train/plugins/profile/2021_06_17_01_31_02/7aaf0e7f661b.memory_profile.json.gz (stored 0%)\n",
            "  adding: content/temp/train/plugins/profile/2021_06_17_01_31_02/7aaf0e7f661b.trace.json.gz (deflated 0%)\n",
            "  adding: content/temp/train/plugins/profile/2021_06_17_01_31_02/7aaf0e7f661b.overview_page.pb (deflated 61%)\n",
            "  adding: content/temp/train/plugins/profile/2021_06_17_01_31_02/7aaf0e7f661b.xplane.pb (deflated 81%)\n",
            "  adding: content/temp/train/plugins/profile/2021_06_17_01_31_02/7aaf0e7f661b.input_pipeline.pb (deflated 56%)\n",
            "  adding: content/temp/metrics/ (stored 0%)\n",
            "  adding: content/temp/metrics/events.out.tfevents.1623893457.7aaf0e7f661b.59.33696.v2 (deflated 72%)\n",
            "  adding: content/temp/validation/ (stored 0%)\n",
            "  adding: content/temp/validation/events.out.tfevents.1623893481.7aaf0e7f661b.59.55531.v2 (deflated 48%)\n",
            "  adding: content/pruned_fashion_mnist_model/ (stored 0%)\n",
            "  adding: content/pruned_fashion_mnist_model/variables/ (stored 0%)\n",
            "  adding: content/pruned_fashion_mnist_model/variables/variables.index (deflated 61%)\n",
            "  adding: content/pruned_fashion_mnist_model/variables/variables.data-00000-of-00001 (deflated 70%)\n",
            "  adding: content/pruned_fashion_mnist_model/saved_model.pb (deflated 90%)\n",
            "  adding: content/pruned_fashion_mnist_model/keras_metadata.pb (deflated 93%)\n",
            "  adding: content/pruned_fashion_mnist_model/assets/ (stored 0%)\n",
            "  adding: content/tflite_qaware_model.tflite (deflated 53%)\n",
            "  adding: content/teacher_model/ (stored 0%)\n",
            "  adding: content/teacher_model/variables/ (stored 0%)\n",
            "  adding: content/teacher_model/variables/variables.index (deflated 70%)\n",
            "  adding: content/teacher_model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: content/teacher_model/saved_model.pb (deflated 90%)\n",
            "  adding: content/teacher_model/keras_metadata.pb (deflated 93%)\n",
            "  adding: content/teacher_model/assets/ (stored 0%)\n",
            "  adding: content/qaware_fashion_mnist_model/ (stored 0%)\n",
            "  adding: content/qaware_fashion_mnist_model/variables/ (stored 0%)\n",
            "  adding: content/qaware_fashion_mnist_model/variables/variables.index (deflated 72%)\n",
            "  adding: content/qaware_fashion_mnist_model/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/qaware_fashion_mnist_model/saved_model.pb (deflated 90%)\n",
            "  adding: content/qaware_fashion_mnist_model/keras_metadata.pb (deflated 94%)\n",
            "  adding: content/qaware_fashion_mnist_model/assets/ (stored 0%)\n",
            "  adding: content/sample_data/ (stored 0%)\n",
            "  adding: content/sample_data/anscombe.json (deflated 83%)\n",
            "  adding: content/sample_data/README.md (deflated 42%)\n",
            "  adding: content/sample_data/mnist_test.csv (deflated 88%)\n",
            "  adding: content/sample_data/mnist_train_small.csv (deflated 88%)\n",
            "  adding: content/sample_data/california_housing_test.csv (deflated 76%)\n",
            "  adding: content/sample_data/california_housing_train.csv (deflated 79%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4c8b29f6-fc80-4b1b-89a6-32c4b541c53d\", \"content.zip\", 67088102)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}